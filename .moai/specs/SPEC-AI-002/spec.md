# SPEC-AI-002: AI/ML 엔진 구현 완성

## 메타데이터

| 항목 | 값 |
|------|------|
| **SPEC ID** | SPEC-AI-002 |
| **제목** | AI/ML 엔진 구현 완성 |
| **상태** | Planned |
| **우선순위** | High |
| **작성일** | 2026-01-18 |
| **도메인** | AI/ML |
| **라벨** | ai, ml, bert, ner, tflite, korean |

## 개요

Momentum 프로젝트의 핵심 AI/ML 엔진 기능을 완성합니다. 현재 기본 구조가 약 40-50% 완성된 상태로, Google ML Kit 기반 OCR 서비스는 구현되었으나 BERT 기반 의도 분류와 NER 기반 개체명 인식 모델 통합이 필요합니다.

## 환경

### 시스템 환경
- **플랫폼**: React Native 0.73.6 (iOS, Android)
- **언어**: TypeScript 5.3+
- **노드 버전**: 18+

### 기술 스택
| 구성 요소 | 기술 | 버전 | 목적 |
|-----------|------|------|------|
| ML Framework | TensorFlow Lite | 2.0.0+ | 온디바이스 ML 추론 |
| OCR | Google ML Kit | 2.0.0 | 텍스트 추출 (완료) |
| 상태 관리 | Zustand | 4.5+ | 전역 상태 |
| 데이터베이스 | SQLite (SQLCipher) | - | 암호화 로컬 저장 |

### 아키텍처 원칙
- **Privacy First**: 모든 AI 처리는 온디바이스에서 수행
- **배터리 최적화**: GPU 대리자, 지연 로딩, 양자화 활용
- **하이브리드 접근**: ML 모델 우선, 정규식 폴백
- **한국어 지원**: KcBERT/KoBERT 모델 활용

## 가정

### 기술적 가정
1. TensorFlow Lite 모델 파일(.tflite)은 앱 번들에 포함 가능
2. KcBERT/KoBERT 모델을 TFLite로 변환하여 모바일에서 실행 가능
3. GPU 대리자(GPU Delegate)를 통해 추론 속도 향상 가능

### 비즈니스 가정
1. 사용자는 온디바이스 처리로 인한 약간의 정확도 저하를 수용 가능
2. 초기 출시 후 80% 이상의 테스트 커버리지 달성 필요

### 위험 요소
- **모델 크기**: BERT 모델이 앱 번들 크기를 크게 증가시킬 수 있음
- **성능**: 저사양 기기에서 추론 속도가 500ms를 초과할 수 있음
- **한국어 모델**: TFLite 변환 시 호환성 문제 가능

## 요구사항 (EARS 형식)

### Ubiquitous Requirements (시스템 전체 항시 적용)

**REQ-AI-001**: 시스템은 **항상** 모든 AI 처리를 온디바이스에서 수행해야 한다
- **이유**: 개인정보 보호 및 프라이버시 원칙 준수
- **검증**: 네트워크 트래픽 모니터링으로 온디바이스 처리 확인

**REQ-AI-002**: 시스템은 **항상** 배터리 소모를 최소화해야 한다
- **기준**: 백그라운드 처리 시 추가 배터리 소모 <5%
- **검증**: 배터리 프로파일링 도구로 측정

**REQ-AI-003**: 시스템은 **항상** ML 모델 실패 시 정규식 폴백을 제공해야 한다
- **이유**: 안정성 확보를 위한 하이브리드 접근
- **검증**: 모델 로딩 실패 시 정규식 기반 분석 작동 확인

### Event-Driven Requirements (이벤트 기반)

**REQ-AI-101**: **WHEN** 사용자가 스크린샷을 캡처하면, 시스템은 **즉시** OCR을 실행하여 텍스트를 추출해야 한다
- **입력**: 이미지 파일 경로
- **출력**: 추출된 텍스트 및 신뢰도 점수
- **성능 기준**: OCR 처리 시간 <1초

**REQ-AI-102**: **WHEN** 텍스트가 추출되면, 시스템은 **즉시** BERT 모델을 통해 의도를 분류해야 한다
- **지원 의도**: social, shopping, work, personal, other
- **출력**: 의도 타입 및 신뢰도 점수
- **성능 기준**: 추론 시간 <500ms

**REQ-AI-103**: **WHEN** 의도 분류가 완료되면, 시스템은 **즉시** NER 모델을 통해 개체명을 추출해야 한다
- **추출 엔티티**: 날짜, 시간, 장소, 금액, 인물, 조직
- **출력**: 엔티티 리스트 및 신뢰도 점수
- **성능 기준**: 추론 시간 <300ms

**REQ-AI-104**: **WHEN** 분석이 완료되면, 시스템은 **즉시** 실행 가능한 액션을 제안해야 한다
- **액션 타입**: 캘린더 등록, 송금, 위시리스트 추가, 알림
- **출력**: 액션 리스트 및 실행 가능 상태

### State-Driven Requirements (상태 기반)

**REQ-AI-201**: **IF** BERT 모델이 로딩되지 않은 상태이면, 시스템은 첫 분류 요청 시 모델을 로딩해야 한다
- **최초 로딩 시간**: <3초
- **이후 요청**: 캐시된 모델 사용

**REQ-AI-202**: **IF** NER 모델이 활성화된 상태이면, 시스템은 ML 기반 엔티티 추출을 우선 사용해야 한다
- **폴백**: ML 실패 시 정규식 패턴 사용

**REQ-AI-203**: **IF** 신뢰도 점수가 임계값(0.6) 미만이면, 시스템은 키워드 기반 분류로 폴백해야 한다
- **임계값 설정**: minConfidence 파라미터로 조절 가능

### Unwanted Requirements (금지 동작)

**REQ-AI-301**: 시스템은 **절대로** 개인정보를 원격 서버로 전송해서는 안 된다
- **검증**: 네트워크 로그 분석

**REQ-AI-302**: 시스템은 **절대로** ML 모델 로딩 실패 시 앱 충돌을 일으켜서는 안 된다
- **대신**: 정규식 폴백 사용

**REQ-AI-303**: 시스템은 **절대로** 사용자 동의 없이 백그라운드에서 추론을 실행해서는 안 된다
- **예외**: 사용자가 명시적으로 동의한 경우

### Optional Requirements (선택적 기능)

**REQ-AI-401**: **가능하면** GPU 가속을 지원해야 한다
- **지원 플랫폼**: Android (GPU Delegate)
- **예상 성능 향상**: 30-50%

**REQ-AI-402**: **가능하면** 모델 양자화를 지원해야 한다
- **목표**: 모델 크기 50% 감소
- **정확도 손실**: <2%

**REQ-AI-403**: **가능하면** 배치 처리를 지원해야 한다
- **용도**: 여러 컨텍스트 동시 분석
- **성능 향상**: 20-30%

## 세부 사양

### SP-AI-001: BERT 모델 통합

**목표**: KcBERT 기반 의도 분류 모델을 TFLite로 변환하고 통합

**모델 사양**:
- **기반 모델**: KcBERT (Korean Comments BERT)
- **입력**: 텍스트 (최대 128 토큰)
- **출력**: 5개 의도类别별 확률 분포
- **모델 크기**: <50MB (양자화 후)

**구현 단계**:
1. KcBERT 모델을 TFLite로 변환
2. 토크나이저 통합 (WordPiece/Morpheme)
3. TensorFlow Lite 로딩 로직 구현
4. GPU 대리자 통합 (Android)
5. 추론 파이프라인 구현

### SP-AI-002: NER 모델 통합

**목표**: KoBERT 기반 개체명 인식 모델을 통합

**모델 사양**:
- **기반 모델**: KoBERT-NER
- **입력**: 텍스트 (최대 256 토큰)
- **출력**: BIO 태그 시퀀스 (PER, LOC, ORG, DAT, MNY, TIM)
- **모델 크기**: <80MB (양자화 후)

**지원 엔티티 타입**:
| 태그 | 설명 | 예시 |
|-----|------|------|
| PER | 인물 | 김철수, John Doe |
| LOC | 장소 | 서울, 강남역 |
| ORG | 조직 | 삼성전자, 서울대 |
| DAT | 날짜 | 2025년 1월 15일 |
| MNY | 금액 | 50,000원 |
| TIM | 시간 | 오후 3시 |

### SP-AI-003: 성능 최적화

**목표**: 모바일 환경에서의 효율적인 ML 실행

**최적화 기법**:
1. **모델 양자화**: FP32 → INT8 (INT8 양자화)
2. **GPU 가속**: Android GPU Delegate 활용
3. **지연 로딩**: 모델 파일 첫 사용 시 로드
4. **결과 캐싱**: 동일 입력에 대한 재계산 방지
5. **배치 처리**: 여러 입력 동시 추론

**성능 목표**:
| 메트릭 | 목표 | 현재 |
|--------|------|------|
| 의도 분류 추론 속도 | <500ms | Mock |
| 엔티티 추출 추론 속도 | <300ms | Regex |
| 배터리 영향 | <5% | 측정 필요 |
| 메모리 사용 | <100MB | 측정 필요 |
| 앱 번들 크기 증가 | <150MB | 측정 필요 |

### SP-AI-004: 테스트 커버리지

**목표**: AI/ML 서비스의 포괄적인 테스트 작성

**커버리지 목표**:
- **Phase 1**: 60% 커버리지 (최소 실행 가능)
- **Phase 2**: 80% 커버리지 (프로덕션 준비)

**테스트 범주**:
1. **Unit Tests**: 각 서비스 클래스별 테스트
2. **Integration Tests**: 파이프라인 테스트
3. **Performance Tests**: 추론 속도 측정
4. **Privacy Tests**: 온디바이스 처리 검증

## 추적성 태그

| 요구사항 | 관련 컴포넌트 | 테스트 시나리오 |
|----------|--------------|----------------|
| REQ-AI-001 | IntentClassifier, EntityExtractor | PRIV-001 |
| REQ-AI-002 | TFLiteService | PERF-001 |
| REQ-AI-003 | IntentClassifier (fallback) | REL-001 |
| REQ-AI-101 | OCRService | OCR-001 |
| REQ-AI-102 | IntentClassifier | INT-001 |
| REQ-AI-103 | EntityExtractor | NER-001 |
| REQ-AI-104 | ContextAnalyzerService | ACT-001 |
| REQ-AI-201 | IntentClassifier (lazy load) | LOAD-001 |
| REQ-AI-202 | EntityExtractor (NER toggle) | NER-002 |
| REQ-AI-203 | IntentClassifier (threshold) | THRESH-001 |
| REQ-AI-301 | NetworkMonitor | PRIV-002 |
| REQ-AI-302 | IntentClassifier (error handling) | ERR-001 |
| REQ-AI-303 | BackgroundScheduler | BG-001 |
| REQ-AI-401 | TFLiteGPUDelegate | PERF-002 |
| REQ-AI-402 | QuantizedModels | PERF-003 |
| REQ-AI-403 | BatchProcessor | BATCH-001 |

---

**버전**: 1.0.0
**마지막 업데이트**: 2026-01-18
**작성자**: Spec Builder Agent
